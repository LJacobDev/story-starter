# Copilot Working Memory Reference

## Current Project State
- **Last Known Good State**: All unit tests passing; auth + email verification working on GitHub Pages with hash routing; logout is idempotent and persistent.
- **Currently Working**: Phase 3 — 3.1.2a useStories TDD. Initial tests and implementation added.
- **Last Test Results**: All tests green (141/141). Some expected Vue router warnings in unit tests without a router; harmless.
- **Known Issues**:
  - Some legacy files/tests may be redundant; defer cleanup until after Phase 3 MVP.

## Key File Relationships
- `src/components/stories/StoryCard.vue` provides accessible image/fallback.
- `src/components/stories/StoryGrid.vue` consumes StoryCard.
- `src/views/Home.vue` renders sections with StoryGrid (placeholder data for now).
- `src/composables/useStories.ts` now encapsulates story fetching, pagination, filtering, and search.

## Recent Changes Made
- [2025-09-18]: Added `tests/unit/useStories.spec.ts` to drive TDD for data fetching (public/mine, pagination, search across title/content/genre/description, type/privacy filters, exact count, hasMore, error handling).
- [2025-09-18]: Implemented `src/composables/useStories.ts` with `fetchPublic` and `fetchMine`, internal `runQuery` handling ordering, count: 'exact', search OR, and pagination with hasMore logic. All tests pass.

## Next Steps Plan (Phase 3)
1. 3.1.2b — Integrate `useStories` into `Home.vue`:
   - Replace placeholders, wire loading/empty/error states, and add "Show more" to append pages.
   - For guests, include marketing hero beside/above grid per spec.
   - TDD: create Home integration tests (loading, append, error, empty).
2. 3.1.2c — Search and filter UI controls with tests.

## Verification Plan
- Unit: `useStories.spec.ts` asserts exact count, ordered queries, correct range, and hasMore computation; search/type/privacy filters; error propagation.
- Manual (later when integrated): navigate Home and verify paging and states.

## Rollback Plan
- If regressions occur, revert `useStories.ts` and tests, and restore placeholder data in Home.

## Human-parsable summary
- Added a tested `useStories` composable using Supabase query builder with exact counts and pagination. Suite now 141/141 passing. Ready to integrate into Home with "Show more" and marketing content for guests.

---

Update timestamp: 2025-09-18. Maintain this file before and after each major task.



## Context Section about Phase 4 Planning (Generated by another model in ask mode — agents, don’t directly edit this section but be aware of it)

Purpose
- Deliver LLM-based story generation via a minimal Supabase Edge Function proxy (“gemini-proxy”) that only sanitizes inputs/outputs and enforces basic limits/rate‑limits. All prompt engineering and output parsing happen on the frontend.
- Phase 4 is the MVP for generation; Phase 6 adds advanced controls (seed lock, custom types, richer undo, metadata persistence).

User journey
- User clicks “Generate New Story.”
- A form collects structured prompts:
  - Story type: short-story | movie-summary | tv-commercial. Internally stored as hyphen‑slugs; UI displays labels with spaces (“Short story,” “Movie summary,” “TV commercial”).
  - Optional title, genre, tone, creativity.
  - Dynamic tags: themes, plot points.
  - Dynamic characters: name, role (protagonist/antagonist/ally/other), optional description.
  - Free‑text “additional instructions” (warn if > 800 chars; allow up to 2000).
  - Optional image (upload to Supabase Storage or paste URL).
  - Privacy toggle (default private; user can opt‑in to public).
- Submit:
  - Frontend constructs the full model prompt string (prompt engineering lives entirely in the client).
  - Frontend instructs Gemini to return strict JSON (via prompt content).
  - Frontend POSTs that final prompt string to the gemini‑proxy Edge Function.
- Edge Function behavior:
  - Validates request size and rate limits.
  - Sanitizes the incoming prompt (trim/collapse whitespace, strip obvious HTML/scripts/control characters).
  - Forwards the sanitized prompt to Gemini as‑is (no server-side templating or schema instructions).
  - Receives Gemini text, sanitizes it (remove BOM, dangerous tags, normalize whitespace; optionally pass through code‑fences untouched).
  - Returns sanitized text to the frontend without parsing or reformatting.
- Frontend then:
  - Cleans fences/backticks if needed, extracts JSON, validates against the client schema, and shows a preview.
  - From preview: Save (persist), Retry (fresh sample) with Undo to restore previous preview, Edit prompts (return to form), or Discard (no persistence).
  - Drafts remain in memory only until Save (no “draft” rows in DB for Phase 4).

Data conventions and limits
- Story types: hyphen slugs in DB/APIs; space‑separated labels in UI.
- Images:
  - Allowed types: png, jpeg, webp.
  - Max size: 2 MB.
  - Dimensions: min 200×200, max 4000×4000; any aspect ratio.
  - Stored in bucket story-covers with owner‑only RLS; display via signed URLs.
  - If none, show type‑specific monochrome SVG fallback (decorative, aria‑hidden):
    - Short story → open book (slate/gray).
    - Movie summary → filmstrip (indigo/blue).
    - TV commercial → clapperboard or megaphone (emerald/green).
- Input validation (client) and guidance:
  - Title ≤ 120; Genre ≤ 60; Tone ≤ 60.
  - Themes ≤ 10, each ≤ 30.
  - Plot points ≤ 10, each ≤ 200.
  - Characters ≤ 6; name ≤ 60; description ≤ 400; role is enum.
  - Additional instructions ≤ 2000; warn when > 800 (latency hint).
- Server safeguards (edge):
  - Enforce reasonable total input budget (~6000 chars) and moderate rate limits.
  - Return sanitized model text; do not attempt JSON parsing.

Privacy and access control
- Default is_private = true on the form; Save preserves user choice.
- RLS: anon can read public; authenticated can read public + own; writes are owner‑only with WITH CHECK.

Retry/Undo semantics
- Retry always requests a fresh sample (no deterministic seed in Phase 4).
- When a retry completes, the preview is replaced; Undo restores the prior preview (single‑level undo).
- Phase 6 will add a visible “Lock seed” toggle for deterministic generations, and deeper undo for text fields.

Responsibilities split
- Frontend:
  - Prompt builder: composes final model prompt, includes strict “respond only with JSON” instructions and the JSON schema description.
  - Calls gemini‑proxy with the prompt string.
  - Extracts and parses JSON from the sanitized text; validates schema; handles user‑visible errors.
  - Image validation/upload, preview, save flow, idempotency on Save, toasts.
- Edge function:
  - Safety and hygiene only: input/output sanitization, size caps, moderate per‑user rate limits (e.g., default: ~8/min, 60/hour, 200/day — adjustable via env).
  - Transparent pass‑through to Gemini; no server‑side templating or response shaping beyond sanitization.
  - Clear error taxonomy: 400 validation, 429 rate limit with Retry‑After, 5xx transient.

Out of scope for Phase 4 (defer to Phase 6+)
- Custom story types authored by users.
- Persisting generation request metadata (prompts/settings) in DB.
- Deterministic seed controls (add visible “Lock seed” toggle later).
- Multi‑level undo for form editors.
- AI image generation.

Quality gates for Phase 4
- TDD for form behavior, prompt builder, client parsing, preview/save/undo, image pipeline, and edge function contract (sanitization + rate limit).
- Manual checklist includes privacy default, length caps/warnings, upload constraints, retry→undo, 429 handling UX, and basic a11y.

Key risks and mitigations
- Non‑JSON model replies → robust client extraction and schema validation; friendly parse errors.
- Latency → input caps and 800‑char warning; visible progress; no server templating to keep flow simple.
- Duplicate saves → client idempotency key; disable Save while pending.
- Storage misuse → client/type/size/dimension checks + bucket RLS; signed URLs only.





# note added by developer

I will want to take all the tests and code in this repo and put it in a repomix set to make sure that they're sensible and covering things well

Claude Sonnet 4 had huge problems at around task 2.1.1, 2.1.2, where it couldn't solve an authentication / validation glitch where the sign in fields kept showing 'field required' and disabling the 'sign in' button, even when filled properly.  It took Claude lots of effort and the use of a repomix file set to try to debug this and it still failed to solve it.

It kept saying confidently that it could definitely see the problem, and then it proceeded to apply extensive and various code changes that would have no effect on the problematic UI behaviour.  Claude sonnet 4 was not able to get the true sign in form to work, but it was able to make a 'test authentication' component that was able to sign in.  When asked to make the sign in form work using the same logic as the working test authentication form, it could not achieve this even though it said that they were matching exactly.

I was about to roll back the repo to a prior checkpoint or try deleting all the related files and building them again, but somehow just switching to GPT-5 mini was enough for it to read the repomix and look at the problem, and understand that there was an issue with v-model not connecting the fields to the validator logic properly and the authentication issue was solved.

GPT-5 mini was then far more helpful for being able to troubleshoot further errors with supabase authentication tokens, vite environment variables, and detecting whether github environment secrets were successfully being injected in github action workflows. GPT-5 mini was also able to make the true sign in form work with the same logic as the test authentication component and get the project back on track.

So at this point, the project is switching from having claude Sonnet 4 be the coding agent to having GPT-5 mini be the coding agent for a (currently) much more effective, informative, and time-saving experience.

Claude in agent mode would go ahead and make speculative changes in hopes of them working, and so there are a lot of strange files left over like old .ts files left in place just so that tests that used to expect them can still pass.  Soon, it will be important to look for and clean up such unneeded files and tests.

